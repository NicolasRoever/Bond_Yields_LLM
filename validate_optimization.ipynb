{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import dspy\n",
    "import numpy as np\n",
    "from dspy.evaluate.metrics import answer_exact_match\n",
    "import pandas as pd\n",
    "from IPython.core.display import Markdown\n",
    "from dspy import Example\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "from dspy.evaluate import Evaluate\n",
    "from module_v002 import FullLLMChain\n",
    "from optimize import passage_similarity_metric, custom_evaluation_function, similar_score_metric, evaluate_expectations_metric, create_dataframe_with_validation_results\n",
    "import json\n",
    "from data.preprocess import create_dspy_examples_train_test_validation_sets\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "llama3_8b = dspy.OllamaLocal(model = \"llama3:8b\",\n",
    "                             temperature = 0,\n",
    "                             max_tokens = 800)\n",
    "\n",
    "gpt35turbo = dspy.OpenAI(model = \"gpt-3.5-turbo-0125\",\n",
    "                         api_key = openai_api_key,\n",
    "                         temperature = 0,\n",
    "                         max_tokens = 800,\n",
    "                         model_type = \"chat\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and Create Training, Testing, Validation Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"data/300_snippets_transcripts_all_labeled_v002.xlsx\")\n",
    "\n",
    "train_examples, test_examples, validation_examples = create_dspy_examples_train_test_validation_sets(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run with the Unoptimzed GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(lm=llama3_8b)\n",
    "full_llm_chain_unoptimized = FullLLMChain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "results_unoptimized = create_dataframe_with_validation_results(\n",
    "    validation_examples=validation_examples[0:2],\n",
    "    llm_chain=full_llm_chain_unoptimized\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_unoptimized = results_unoptimized[\"Evaluation_Score\"].mean()\n",
    "metric_unoptimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Country Keyword: German\\nCountry Role: \\nExcerpt:'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_unoptimized[\"Rationale\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run with the Optimized GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(lm=llama3_8b)\n",
    "\n",
    "full_llm_chain_optimized = FullLLMChain()\n",
    "full_llm_chain_optimized.load(path=\"optimized_llm_chains/optimized_llama_chain_v002.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_optimized = create_dataframe_with_validation_results(\n",
    "    validation_examples=validation_examples[0:2],\n",
    "    llm_chain=full_llm_chain_unoptimized,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_optimized = results_unoptimized[\"Evaluation_Score\"].mean()\n",
    "metric_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_optimized.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
